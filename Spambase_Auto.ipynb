{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "import mnist \n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import homogeneity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3680, 57), (3680,), (921, 57), (921,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data \n",
    "path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "data = pd.read_csv(path, header = None)\n",
    "\n",
    "#splitting 20% data into test and 80 % into train \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.iloc[:,0:57], data.iloc[:,57], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Average Train Eror: 3564.5937890625\n",
      "\n",
      " Test Error 11645.432\n",
      "Epoch: 3 \t Average Train Eror: 10218.362333984374\n",
      "\n",
      " Test Error 11645.388\n",
      "Epoch: 5 \t Average Train Eror: 13361.203203125\n",
      "\n",
      " Test Error 11645.385\n",
      "Epoch: 7 \t Average Train Eror: 4458.504448242187\n",
      "\n",
      " Test Error 11645.386\n",
      "Epoch: 9 \t Average Train Eror: 6867.049672851563\n",
      "\n",
      " Test Error 11645.385\n",
      "Logistic Regression\n",
      "The training accuracy is  0.653804347826087\n",
      "The testing accuracy is  0.6568946796959826\n",
      "K-means Clustering\n",
      "score-1873.114649772644\n",
      "Train purity score 0.06504292234112254\n",
      "Test purity score 0.1025766599792918\n"
     ]
    }
   ],
   "source": [
    "inputs = 57\n",
    "hidden_layer = 20\n",
    "output_layer = inputs\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, inputs]) #flattened shape\n",
    "\n",
    "tf.set_random_seed(42)\n",
    "W = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([inputs, hidden_layer])),\n",
    "    'decoder_h1':tf.Variable(tf.random_normal([hidden_layer, output_layer]))\n",
    "}\n",
    "\n",
    "B = {\n",
    "    'encoder_h1':tf.Variable(tf.random_normal([hidden_layer])),\n",
    "    'decoder_h1':tf.Variable(tf.random_normal([output_layer]))\n",
    "}\n",
    "\n",
    "encoder = tf.nn.sigmoid(tf.matmul(X,W['encoder_h1']) +  B['encoder_h1'])\n",
    "\n",
    "decoder = tf.nn.sigmoid(tf.matmul(encoder,W['decoder_h1'])  + B['decoder_h1'])\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "Y = X\n",
    "loss = tf.reduce_mean(tf.pow(decoder - Y, 2))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "def get_batches(batch_size,x):\n",
    "        indexes = list(range(x.shape[0]))\n",
    "        random.shuffle(indexes)\n",
    "        ind = indexes[:batch_size]\n",
    "        return(x[ind])\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        train_c = 0                                                       #cost\n",
    "        total_batch = int(X_train.shape[0]/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x = get_batches(batch_size, np.array(X_train))\n",
    "            _,train_c = sess.run([optimizer, loss], feed_dict = {X: batch_x})\n",
    "            train_c += train_c/batch_size    \n",
    "        if epoch % 2 == 0:\n",
    "            print(\"Epoch:\",epoch+1,\"\\t Average Train Eror:\",train_c)  \n",
    "            test_c = sess.run(loss,feed_dict = {X:np.array(X_test)})\n",
    "            print(\"\\n Test Error\", test_c)    \n",
    "    encoder_train, decoder_train = sess.run([encoder,decoder],feed_dict = {X:np.array(X_train)})\n",
    "    encoder_test, decoder_test = sess.run([encoder,decoder],feed_dict = {X:np.array(X_test)})\n",
    "    \n",
    "#For Classification Task:\n",
    "print(\"Logistic Regression\")\n",
    "loReg = LogisticRegression(penalty='l2',solver = 'lbfgs',multi_class='multinomial')\n",
    "loReg.fit(encoder_train,Y_train)\n",
    "\n",
    "score = loReg.score(encoder_train, Y_train)\n",
    "print(\"The training accuracy is \",score)\n",
    "\n",
    "score = loReg.score(encoder_test,Y_test)\n",
    "print(\"The testing accuracy is \",score)\n",
    "\n",
    "#Clustering task:\n",
    "print(\"K-means Clustering\")\n",
    "cluster = KMeans(n_clusters=3)\n",
    "cluster.fit(encoder_train)\n",
    "print(\"Train purity score\", homogeneity_score(Y_train, cluster.predict(encoder_train)))\n",
    "print(\"Test purity score\", homogeneity_score(Y_test, cluster.predict(encoder_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Average Train Eror: 4886.806586914063\n",
      "\n",
      " Test Error 11644.824\n",
      "Epoch: 3 \t Average Train Eror: 3251.2215625\n",
      "\n",
      " Test Error 11643.377\n",
      "Epoch: 5 \t Average Train Eror: 24173.86669921875\n",
      "\n",
      " Test Error 11643.361\n",
      "Epoch: 7 \t Average Train Eror: 3858.7836596679685\n",
      "\n",
      " Test Error 11643.355\n",
      "Epoch: 9 \t Average Train Eror: 6501.110102539063\n",
      "\n",
      " Test Error 11643.352\n",
      "Epoch: 11 \t Average Train Eror: 7727.328515625\n",
      "\n",
      " Test Error 11643.339\n",
      "Epoch: 13 \t Average Train Eror: 39363.53484375\n",
      "\n",
      " Test Error 11643.334\n",
      "Epoch: 15 \t Average Train Eror: 2429.161208496094\n",
      "\n",
      " Test Error 11643.329\n",
      "Epoch: 17 \t Average Train Eror: 6129.628354492187\n",
      "\n",
      " Test Error 11643.327\n",
      "Epoch: 19 \t Average Train Eror: 6047.740434570313\n",
      "\n",
      " Test Error 11643.319\n",
      "Logistic Regression\n",
      "The training accuracy is  0.8565217391304348\n",
      "The testing accuracy is  0.8621064060803475\n",
      "K-means Clustering\n",
      "Train purity score 0.35956635421357147\n",
      "Test purity score 0.3549492816596936\n"
     ]
    }
   ],
   "source": [
    "inputs = 57\n",
    "hidden_layer = 20\n",
    "output_layer = inputs\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, inputs]) #flattened shape\n",
    "\n",
    "tf.set_random_seed(42)\n",
    "W = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([inputs, hidden_layer])),\n",
    "    'decoder_h1':tf.Variable(tf.random_normal([hidden_layer, output_layer]))\n",
    "}\n",
    "\n",
    "B = {\n",
    "    'encoder_h1':tf.Variable(tf.random_normal([hidden_layer])),\n",
    "    'decoder_h1':tf.Variable(tf.random_normal([output_layer]))\n",
    "}\n",
    "\n",
    "encoder = tf.nn.sigmoid(tf.matmul(X,W['encoder_h1']) +  B['encoder_h1'])\n",
    "\n",
    "decoder = tf.nn.sigmoid(tf.matmul(encoder,W['decoder_h1'])  + B['decoder_h1'])\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "Y = X\n",
    "loss = tf.reduce_mean(tf.pow(decoder - Y, 2))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "def get_batches(batch_size,x):\n",
    "        indexes = list(range(x.shape[0]))\n",
    "        random.shuffle(indexes)\n",
    "        ind = indexes[:batch_size]\n",
    "        return(x[ind])\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        train_c = 0                                                       #cost\n",
    "        total_batch = int(X_train.shape[0]/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x = get_batches(batch_size, np.array(X_train))\n",
    "            _,train_c = sess.run([optimizer, loss], feed_dict = {X: batch_x})\n",
    "            train_c += train_c/batch_size    \n",
    "        if epoch % 2 == 0:\n",
    "            print(\"Epoch:\",epoch+1,\"\\t Average Train Eror:\",train_c)  \n",
    "            test_c = sess.run(loss,feed_dict = {X:np.array(X_test)})\n",
    "            print(\"\\n Test Error\", test_c)    \n",
    "    encoder_train, decoder_train = sess.run([encoder,decoder],feed_dict = {X:np.array(X_train)})\n",
    "    encoder_test, decoder_test = sess.run([encoder,decoder],feed_dict = {X:np.array(X_test)})\n",
    "    \n",
    "#For Classification Task:\n",
    "print(\"Logistic Regression\")\n",
    "loReg = LogisticRegression(penalty='l2',solver = 'lbfgs',multi_class='multinomial')\n",
    "loReg.fit(encoder_train,Y_train)\n",
    "\n",
    "score = loReg.score(encoder_train, Y_train)\n",
    "print(\"The training accuracy is \",score)\n",
    "\n",
    "score = loReg.score(encoder_test,Y_test)\n",
    "print(\"The testing accuracy is \",score)\n",
    "\n",
    "#Clustering task:\n",
    "print(\"K-means Clustering\")\n",
    "cluster = KMeans(n_clusters=3)\n",
    "cluster.fit(encoder_train)\n",
    "print(\"Train purity score\", homogeneity_score(Y_train, cluster.predict(encoder_train)))\n",
    "print(\"Test purity score\", homogeneity_score(Y_test, cluster.predict(encoder_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Average Train Eror: 3510.832741699219\n",
      "\n",
      " Test Error 11643.386\n",
      "Epoch: 3 \t Average Train Eror: 3375.0397705078126\n",
      "\n",
      " Test Error 11643.365\n",
      "Epoch: 5 \t Average Train Eror: 3858.9619384765624\n",
      "\n",
      " Test Error 11643.351\n",
      "Epoch: 7 \t Average Train Eror: 5217.865649414062\n",
      "\n",
      " Test Error 11643.337\n",
      "Epoch: 9 \t Average Train Eror: 39158.5008984375\n",
      "\n",
      " Test Error 11643.331\n",
      "Logistic Regression\n",
      "The training accuracy is  0.8654891304347826\n",
      "The testing accuracy is  0.8599348534201955\n",
      "K-means Clustering\n",
      "Train purity score 0.04208621402465878\n",
      "Test purity score 0.05261939662489349\n"
     ]
    }
   ],
   "source": [
    "inputs = 57\n",
    "hidden_layer = 50\n",
    "output_layer = inputs\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, inputs]) #flattened shape\n",
    "\n",
    "tf.set_random_seed(42)\n",
    "W = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([inputs, hidden_layer])),\n",
    "    'decoder_h1':tf.Variable(tf.random_normal([hidden_layer, output_layer]))\n",
    "}\n",
    "\n",
    "B = {\n",
    "    'encoder_h1':tf.Variable(tf.random_normal([hidden_layer])),\n",
    "    'decoder_h1':tf.Variable(tf.random_normal([output_layer]))\n",
    "}\n",
    "\n",
    "encoder = tf.nn.sigmoid(tf.matmul(X,W['encoder_h1']) +  B['encoder_h1'])\n",
    "\n",
    "decoder = tf.nn.sigmoid(tf.matmul(encoder,W['decoder_h1'])  + B['decoder_h1'])\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "Y = X\n",
    "loss = tf.reduce_mean(tf.pow(decoder - Y, 2))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "def get_batches(batch_size,x):\n",
    "        indexes = list(range(x.shape[0]))\n",
    "        random.shuffle(indexes)\n",
    "        ind = indexes[:batch_size]\n",
    "        return(x[ind])\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        train_c = 0                                                       #cost\n",
    "        total_batch = int(X_train.shape[0]/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x = get_batches(batch_size, np.array(X_train))\n",
    "            _,train_c = sess.run([optimizer, loss], feed_dict = {X: batch_x})\n",
    "            train_c += train_c/batch_size    \n",
    "        if epoch % 2 == 0:\n",
    "            print(\"Epoch:\",epoch+1,\"\\t Average Train Eror:\",train_c)  \n",
    "            test_c = sess.run(loss,feed_dict = {X:np.array(X_test)})\n",
    "            print(\"\\n Test Error\", test_c)    \n",
    "    encoder_train, decoder_train = sess.run([encoder,decoder],feed_dict = {X:np.array(X_train)})\n",
    "    encoder_test, decoder_test = sess.run([encoder,decoder],feed_dict = {X:np.array(X_test)})\n",
    "    \n",
    "#For Classification Task:\n",
    "print(\"Logistic Regression\")\n",
    "loReg = LogisticRegression(penalty='l2',solver = 'lbfgs',multi_class='multinomial')\n",
    "loReg.fit(encoder_train,Y_train)\n",
    "\n",
    "score = loReg.score(encoder_train, Y_train)\n",
    "print(\"The training accuracy is \",score)\n",
    "\n",
    "score = loReg.score(encoder_test,Y_test)\n",
    "print(\"The testing accuracy is \",score)\n",
    "\n",
    "#Clustering task:\n",
    "print(\"K-means Clustering\")\n",
    "cluster = KMeans(n_clusters=3)\n",
    "cluster.fit(encoder_train)\n",
    "print(\"Train purity score\", homogeneity_score(Y_train, cluster.predict(encoder_train)))\n",
    "print(\"Test purity score\", homogeneity_score(Y_test, cluster.predict(encoder_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Average Train Eror: 5466.925336914062\n",
      "\n",
      " Test Error 11643.386\n",
      "Epoch: 3 \t Average Train Eror: 3624.3655200195312\n",
      "\n",
      " Test Error 11643.355\n",
      "Epoch: 5 \t Average Train Eror: 6771.954819335938\n",
      "\n",
      " Test Error 11643.337\n",
      "Epoch: 7 \t Average Train Eror: 6941.78326171875\n",
      "\n",
      " Test Error 11643.329\n",
      "Epoch: 9 \t Average Train Eror: 6137.773452148437\n",
      "\n",
      " Test Error 11643.317\n",
      "Logistic Regression\n",
      "The training accuracy is  0.9008152173913043\n",
      "The testing accuracy is  0.9033659066232356\n",
      "K-means Clustering\n",
      "Train purity score 0.025741860280900582\n",
      "Test purity score 0.023556397428143545\n"
     ]
    }
   ],
   "source": [
    "inputs = 57\n",
    "hidden_layer = 100\n",
    "output_layer = inputs\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, inputs]) #flattened shape\n",
    "\n",
    "tf.set_random_seed(42)\n",
    "W = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([inputs, hidden_layer])),\n",
    "    'decoder_h1':tf.Variable(tf.random_normal([hidden_layer, output_layer]))\n",
    "}\n",
    "\n",
    "B = {\n",
    "    'encoder_h1':tf.Variable(tf.random_normal([hidden_layer])),\n",
    "    'decoder_h1':tf.Variable(tf.random_normal([output_layer]))\n",
    "}\n",
    "\n",
    "encoder = tf.nn.sigmoid(tf.matmul(X,W['encoder_h1']) +  B['encoder_h1'])\n",
    "\n",
    "decoder = tf.nn.sigmoid(tf.matmul(encoder,W['decoder_h1'])  + B['decoder_h1'])\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "Y = X\n",
    "loss = tf.reduce_mean(tf.pow(decoder - Y, 2))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "def get_batches(batch_size,x):\n",
    "        indexes = list(range(x.shape[0]))\n",
    "        random.shuffle(indexes)\n",
    "        ind = indexes[:batch_size]\n",
    "        return(x[ind])\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        train_c = 0                                                       #cost\n",
    "        total_batch = int(X_train.shape[0]/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x = get_batches(batch_size, np.array(X_train))\n",
    "            _,train_c = sess.run([optimizer, loss], feed_dict = {X: batch_x})\n",
    "            train_c += train_c/batch_size    \n",
    "        if epoch % 2 == 0:\n",
    "            print(\"Epoch:\",epoch+1,\"\\t Average Train Eror:\",train_c)  \n",
    "            test_c = sess.run(loss,feed_dict = {X:np.array(X_test)})\n",
    "            print(\"\\n Test Error\", test_c)    \n",
    "    encoder_train, decoder_train = sess.run([encoder,decoder],feed_dict = {X:np.array(X_train)})\n",
    "    encoder_test, decoder_test = sess.run([encoder,decoder],feed_dict = {X:np.array(X_test)})\n",
    "    \n",
    "#For Classification Task:\n",
    "print(\"Logistic Regression\")\n",
    "loReg = LogisticRegression(penalty='l2',solver = 'lbfgs',multi_class='multinomial')\n",
    "loReg.fit(encoder_train,Y_train)\n",
    "\n",
    "score = loReg.score(encoder_train, Y_train)\n",
    "print(\"The training accuracy is \",score)\n",
    "\n",
    "score = loReg.score(encoder_test,Y_test)\n",
    "print(\"The testing accuracy is \",score)\n",
    "\n",
    "#Clustering task:\n",
    "print(\"K-means Clustering\")\n",
    "cluster = KMeans(n_clusters=3)\n",
    "cluster.fit(encoder_train)\n",
    "print(\"Train purity score\", homogeneity_score(Y_train, cluster.predict(encoder_train)))\n",
    "print(\"Test purity score\", homogeneity_score(Y_test, cluster.predict(encoder_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Average Train Eror: 2779.1762646484376\n",
      "\n",
      " Test Error 11643.3955\n",
      "Epoch: 3 \t Average Train Eror: 2179.334157714844\n",
      "\n",
      " Test Error 11643.363\n",
      "Epoch: 5 \t Average Train Eror: 3659.7325341796877\n",
      "\n",
      " Test Error 11643.347\n",
      "Epoch: 7 \t Average Train Eror: 6998.779711914062\n",
      "\n",
      " Test Error 11643.332\n",
      "Epoch: 9 \t Average Train Eror: 6514.037905273438\n",
      "\n",
      " Test Error 11643.324\n",
      "Logistic Regression\n",
      "The training accuracy is  0.9182065217391304\n",
      "The testing accuracy is  0.9066232356134636\n",
      "K-means Clustering\n",
      "Train purity score 0.057766720715459914\n",
      "Test purity score 0.07726340201213858\n"
     ]
    }
   ],
   "source": [
    "inputs = 57\n",
    "hidden_layer = 200\n",
    "output_layer = inputs\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, inputs]) #flattened shape\n",
    "\n",
    "tf.set_random_seed(42)\n",
    "W = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([inputs, hidden_layer])),\n",
    "    'decoder_h1':tf.Variable(tf.random_normal([hidden_layer, output_layer]))\n",
    "}\n",
    "\n",
    "B = {\n",
    "    'encoder_h1':tf.Variable(tf.random_normal([hidden_layer])),\n",
    "    'decoder_h1':tf.Variable(tf.random_normal([output_layer]))\n",
    "}\n",
    "\n",
    "encoder = tf.nn.sigmoid(tf.matmul(X,W['encoder_h1']) +  B['encoder_h1'])\n",
    "\n",
    "decoder = tf.nn.sigmoid(tf.matmul(encoder,W['decoder_h1'])  + B['decoder_h1'])\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "Y = X\n",
    "loss = tf.reduce_mean(tf.pow(decoder - Y, 2))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "def get_batches(batch_size,x):\n",
    "        indexes = list(range(x.shape[0]))\n",
    "        random.shuffle(indexes)\n",
    "        ind = indexes[:batch_size]\n",
    "        return(x[ind])\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        train_c = 0                                                       #cost\n",
    "        total_batch = int(X_train.shape[0]/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x = get_batches(batch_size, np.array(X_train))\n",
    "            _,train_c = sess.run([optimizer, loss], feed_dict = {X: batch_x})\n",
    "            train_c += train_c/batch_size    \n",
    "        if epoch % 2 == 0:\n",
    "            print(\"Epoch:\",epoch+1,\"\\t Average Train Eror:\",train_c)  \n",
    "            test_c = sess.run(loss,feed_dict = {X:np.array(X_test)})\n",
    "            print(\"\\n Test Error\", test_c)    \n",
    "    encoder_train, decoder_train = sess.run([encoder,decoder],feed_dict = {X:np.array(X_train)})\n",
    "    encoder_test, decoder_test = sess.run([encoder,decoder],feed_dict = {X:np.array(X_test)})\n",
    "    \n",
    "#For Classification Task:\n",
    "print(\"Logistic Regression\")\n",
    "loReg = LogisticRegression(penalty='l2',solver = 'lbfgs',multi_class='multinomial')\n",
    "loReg.fit(encoder_train,Y_train)\n",
    "\n",
    "score = loReg.score(encoder_train, Y_train)\n",
    "print(\"The training accuracy is \",score)\n",
    "\n",
    "score = loReg.score(encoder_test,Y_test)\n",
    "print(\"The testing accuracy is \",score)\n",
    "\n",
    "#Clustering task:\n",
    "print(\"K-means Clustering\")\n",
    "cluster = KMeans(n_clusters=3)\n",
    "cluster.fit(encoder_train)\n",
    "print(\"Train purity score\", homogeneity_score(Y_train, cluster.predict(encoder_train)))\n",
    "print(\"Test purity score\", homogeneity_score(Y_test, cluster.predict(encoder_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
